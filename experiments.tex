% !TeX spellcheck = ru_RU

Для количественной оценки результатов работы решения, а также сравнения с предложенных в решении алгоритмических модификаций с алгоритмами, указанными в главе \ref{sec:relatedworks}, был проведен ряд экспериментов.


\subsection{Задачи эксперимента}
В ходе экспериментов были исследованы следующие вопросы:

\textbf{RQ 1: } Насколько качественно производится реконструкция входных изображений в латентном пространстве генеративной состязательной сети с помощью примененного в решении алгоритма по сравнению с существующими state-of-the-art алгоритмами?

\textbf{RQ 2: }Насколько хорошо работает примененный в решении алгоритм переноса признаков по сравнению с существующими state-of-the-art алгоритмами?

%\begin{enumerate}
%    \item 
%    % Оценка качества реконструкции реальных изображений
%    Насколько качественно производится реконструкция входных изображений в латентном пространстве генеративной состязательной сети с помощью примененного в решении алгоритма по сравнению с существующими state-of-the-art алгоритмами?
%    \item 
%    % Оценка качества переноса лицевых признаков
%    Насколько хорошо работает примененный в решении алгоритм переноса признаков по сравнению с существующими state-of-the-art алгоритмами?
%\end{enumerate}


\subsection{Метрики}
% нужны ссылки.
Следуя мотивации, представленной в литературе по генеративным состязательным сетям, были использованы метрики FID, LPIPS, и Face identity score. Кроме того, в качестве сравниваемой метрики использовалось количество времени, затрачиваемое алгоритмом на обработку одного изображения.

\paragraph{FID.} 
Чтобы измерить реалистичность получаемых изображений применяется метрика FID (\emph{Frechet inception distance}) \cite{heusel2017fid}, используемая для измерения качества изображений, сгенерированных с помощью генеративной нейронной сети.
Эта метрика позволяет сравнить распределение сгенерированных изображений, полученных в результате применения оцениваемых алгоритмов, с распределением набора реальных изображений.

\paragraph{LPIPS.}
Для оценки схожести реальных входных изображений и сгенерированных изображений, полученных в результате работы алгоритма, применяется метрика визуальной схожести LPIPS \cite{zhang2018lpips}.

\paragraph{Face identity score.}
Для того, чтобы численно оценить меру сохранения лицевых признаков, которые определяют личность человека, между реальным входным изображением и изображением, реконструированным или отредактированным с помощью генеративной нейронной сети, применяется метрика Face identity score.
Для этого используется нейросетевая модель для распознавания лиц \cite{deng2018arcface}, с помощью которой по изображениям получаются векторные ембеддинги.
По паре изображений, а именно реальному изображению и его реконструкции, или изображению до и после редактирования, вычисляется мера косинусного сходства (\emph{cosine similarity}) между их эмбеддингами.


\subsection{Данные}
Эксперименты были проведены на двух датасетах: CelebA-HQ \cite{progressive-growing-gan} и FEI Face Database \cite{fei-database}.

Датасет CelebA-HQ --- это высококачественная версия набора изображений CelebA \cite{liu2015celeba}, которая содержит $30000$ изображений с расширением $1024\times1024$.
Этот датасет содержит изображения $10177$ различных знаменитостей, полученные путем предобработки и выравнивания реальных фотографий.
Кроме того, для каждого изображения отмечены координаты $5$ особых точек лица и значения $40$ бинарных лицевых признаков.

Датасет FEI Face Database представлет собой набор из $2800$ изображений, полученных в студийных условиях.
Он содержит по $14$ изображений на каждого из $200$ субъектов.
Каждый субъект представлен набором изображений, на которых варьируются такие лицевые признаки, как \emph{положение головы}, \emph{наличие улыбки} и \emph{освещение}.


\subsection{Методология экспериментов}
\paragraph{RQ 1:}
Сравнение качества реконструкции производится со следующими алгоритмами: StyleGAN2 Projector \cite{karras2020stylegan2} и энкодер, используемый в архитектуре ALAE \cite{ALAE}.
Для этого производится отображение изображений, взятых из датасета CelebA-HQ, в латентное пространство соответствующей модели.
Затем подсчитываются метрика реалистичности (FID) и метрики визуальной схожести (LPIPS, Face identity score) между реальным изображением и его реконструкцией.
Также подсчитывается время, затраченное алгоритмом на обработку одного изображения.
Результаты данного эксперимента представлены в Таблице \ref{tab:exp1}.

\begin{table}
\begin{center}
  \caption{Результаты эксперимента по оценке качества реконструкции изображений.}
  \label{tab:exp1}
  \begin{tabular}{ |r|c|c|c|c| } 
    \hline
      & FID ↓ & LPIPS ↓ & F.i.s. ↑ & Время ↓ \\ 
    \hline\hline
    ALAE    & 54.686 & 0.403 & 0.494 & \textbf{0.28s}  \\ 
    StyleGAN2 Projector 
            & \textbf{54.484} & 0.332 & 0.591 & 37.57s  \\ 
    Решение & 68.129 & \textbf{0.248} & \textbf{0.853} & 33.71s  \\ 
    \hline
  \end{tabular}
\end{center}
\end{table}

\paragraph{RQ 2:}
Сравнение качества переноса лицевых признаков производится со следующими алгоритмами: Image2StyleGAN \cite{abdal2019image2stylegan} и GANSpace \cite{hrknen2020ganspace}.
Для данного сравнения в качестве редактируемых признаков были выбраны \emph{положение головы} и \emph{наличие улыбки} на изображении.

Для проведения данного эксперимента изображения, взятые из датасета FEI Face Database, разбиваются на 3 набора: набор входных изображений, на которых отсутствует рассматриваемый признак, набор целевых изображений тех же субъектов, на которых присутствует рассматриваемый признак, и набор изображений-образцов, который не содержит субъектов, изображения которых взяты в качестве входных изображений, и на которых присутствует рассматриваемый признак.
Входные изображения и изображения-образцы отображаются в латентное пространство сети StyleGAN с использованием реализованного в данной работе алгоритма отображения.
Затем к входным изображениям применяется алгоритм переноса признака, котороый использует в качестве изображения-образца случайное изображение из набора изображений-образцов.

Между изображениями, полученными в результате применения алгоритма, и целевыми изображениями подсчитываются метрики визуальной схожести (LPIPS, Face identity score) а также метрика реалистичности (FID).
Также подсчитывается время, затраченное алгоритмом на обработку одного изображения.
Результаты данного эксперимента представлены в Таблице \ref{tab:exp2}.

\begin{table}
\begin{center}
  \caption{Результаты эксперимента по оценке качества переноса лицевых признаков.}
  \label{tab:exp2}
  \begin{tabular}{ |r c|c|c|c|c| } 
    \hline
      & & FID ↓ & LPIPS ↓ & F.i.s. ↑ & Время ↓ \\ 
    \hline\hline
    GANSpace & (\emph{pose}) & 166.630 & 0.352 & 0.582 & 0.344s \\
            & (\emph{smile}) & 147.160 & 0.276 & 0.748 &  \\
    \hline
    Image2StyleGAN 
             & (\emph{pose}) & 155.503 & 0.328 & 0.643 & \textbf{0.314s} \\
            & (\emph{smile}) & 120.609 & \textbf{0.239} & 0.769 & \\
    \hline
    Решение  & (\emph{pose}) & \textbf{148.053} & \textbf{0.319} & \textbf{0.695} & 38.25s \\ 
            & (\emph{smile}) & \textbf{117.021} & 0.241 & \textbf{0.784} &  \\ 
    \hline
  \end{tabular}
\end{center}
\end{table}

\subsection{Анализ результатов}

Как видно из результатов, представленных в табл. \ref{tab:exp1}, реализованный в данном решении алгоритм отображения изображений в латентное пространство генеративной состязательной сети демонстрирует улучшение метрик визуальной схожести LPIPS (на $0.084$) и Face identity score (на $0.262$).
Тем не менее, он демонстрирует ухудшение по метрике реалистичности FID (на $13.645$).
Кроме того, в данном решении удалось ускорить алгоритм латентной оптимазации по сравнению с StyleGAN2 Projector (на $3.86$ c). Несмотря на это, он не может конкурировать по времени работы с алгоритмом ALAE, использующим только энкодер.

Ухудшение метрики реалистичности FID может говорить о возникновении артефактов на генерируемом изображении, связанных с тем, что латентная оптимизация попадает в область латентного пространства, удаленную от распределения первоначальных тренировочных данных.
Поэтому используемая генеративная нейронная сеть испытывает трудности при генерации качественного изображения.
Кроме того, это также может говорить о том, что реализованный алгоритм латентной оптимизации подвержен застреванию в локальном минимуме. Для анализа и решения данной проблемы требуется дальнейшее исследование.

Результаты оценки реализованного в данном решении алгоритма переноса лицевых признаков, представленные в табл. \ref{tab:exp2}, демонстрируют улучшение как метрики реалистичности FID, так и метрик визуальной схожести LPIPS и Face identity score.
Стоит отметить, что более значимых улучшений удается добиться при редактированиии признака \emph{положение головы} (FID на $7.45$, LPIPS на $0.009$, Face identity score на $0.052$).

Тем не менее, реализованный алгоритм демонстрирует увеличение количества времени, затрачиваемого на обработру изображения.
Это связано с итеративной природой алгоритма переноса.
В отличие от алгоритмов GANSpace и Image2StyleGAN, которые единожды применяют линейный сдвиг в латентном пространстве генеративной состязательной сети, в реализованном алгоритме применяется пошаговая оптимизация, в которой на каждом шаге требуется сгенерировать изображение по текущему приближению и скорректировать его для сохранения семантических признаков, определяющих личность.